{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Memory: Building Memory-Enabled Investment Agents with LangGraph\n",
    "\n",
    "In this notebook, we'll explore **agent memory systems** - the ability for AI agents to remember information across interactions. We'll implement all five memory types from the **CoALA (Cognitive Architectures for Language Agents)** framework while building a Stone Ridge Investment Advisory Assistant.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand the 5 memory types from the CoALA framework\n",
    "- Implement short-term memory with checkpointers and thread_id\n",
    "- Build long-term memory with InMemoryStore and namespaces\n",
    "- Use semantic memory for meaning-based retrieval\n",
    "- Apply episodic memory for few-shot learning from past experiences\n",
    "- Create procedural memory for self-improving agents\n",
    "- Combine all memory types into a unified investment advisory agent\n",
    "\n",
    "## Table of Contents:\n",
    "\n",
    "- **Breakout Room #1:** Memory Foundations\n",
    "  - Task 1: Dependencies\n",
    "  - Task 2: Understanding Agent Memory (CoALA Framework)\n",
    "  - Task 3: Short-Term Memory (MemorySaver, thread_id)\n",
    "  - Task 4: Long-Term Memory (InMemoryStore, namespaces)\n",
    "  - Task 5: Message Trimming & Context Management\n",
    "  - Question #1 & Question #2\n",
    "  - üèóÔ∏è Activity #1: Store & Retrieve User Investment Profile\n",
    "\n",
    "- **Breakout Room #2:** Advanced Memory & Integration\n",
    "  - Task 6: Semantic Memory (Embeddings + Search)\n",
    "  - Task 7: Building Semantic Investment Knowledge Base\n",
    "  - Task 8: Episodic Memory (Few-Shot Learning)\n",
    "  - Task 9: Procedural Memory (Self-Improving Agent)\n",
    "  - Task 10: Unified Investment Memory Agent\n",
    "  - Question #3 & Question #4\n",
    "  - üèóÔ∏è Activity #2: Investment Memory Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ü§ù Breakout Room #1\n",
    "## Memory Foundations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Dependencies\n",
    "\n",
    "Before we begin, make sure you have:\n",
    "\n",
    "1. **API Keys** for:\n",
    "   - OpenAI (for GPT-4o-mini and embeddings)\n",
    "   - LangSmith (optional, for tracing)\n",
    "\n",
    "2. **Dependencies installed** via `uv sync`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import os\n",
    "import getpass\n",
    "from uuid import uuid4\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()  # Required for async operations in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set API Keys\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: LangSmith for tracing\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIE9 - Agent Memory - Investment - {uuid4().hex[0:8]}\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangSmith API Key (press Enter to skip): \") or \"\"\n",
    "\n",
    "if not os.environ[\"LANGCHAIN_API_KEY\"]:\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "    print(\"LangSmith tracing disabled\")\n",
    "else:\n",
    "    print(f\"LangSmith tracing enabled. Project: {os.environ['LANGCHAIN_PROJECT']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory systems ready!\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Test the connection\n",
    "response = llm.invoke(\"Say 'Memory systems ready!' in exactly those words.\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Understanding Agent Memory (CoALA Framework)\n",
    "\n",
    "The **CoALA (Cognitive Architectures for Language Agents)** framework identifies 5 types of memory that agents can use:\n",
    "\n",
    "| Memory Type | Human Analogy | AI Implementation | Investment Example |\n",
    "|-------------|---------------|-------------------|------------------|\n",
    "| **Short-term** | What someone just said | Conversation history within a thread | Current investment consultation conversation |\n",
    "| **Long-term** | Remembering a friend's birthday | User preferences stored across sessions | User's risk tolerance, portfolio size, investment goals |\n",
    "| **Semantic** | Knowing Paris is in France | Facts retrieved by meaning | Investment knowledge retrieval |\n",
    "| **Episodic** | Remembering your first day at work | Learning from past experiences | Past successful advisory patterns |\n",
    "| **Procedural** | Knowing how to ride a bike | Self-improving instructions | Learned communication and advisory preferences |\n",
    "\n",
    "### Memory Architecture Overview\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                LangGraph Investment Advisory Agent               ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ                                                                 ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ\n",
    "‚îÇ  ‚îÇ  Short-term  ‚îÇ  ‚îÇ  Long-term   ‚îÇ  ‚îÇ   Semantic   ‚îÇ           ‚îÇ\n",
    "‚îÇ  ‚îÇ    Memory    ‚îÇ  ‚îÇ    Memory    ‚îÇ  ‚îÇ    Memory    ‚îÇ           ‚îÇ\n",
    "‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ           ‚îÇ\n",
    "‚îÇ  ‚îÇ Checkpointer ‚îÇ  ‚îÇ    Store     ‚îÇ  ‚îÇStore+Embed   ‚îÇ           ‚îÇ\n",
    "‚îÇ  ‚îÇ + thread_id  ‚îÇ  ‚îÇ + namespace  ‚îÇ  ‚îÇ  + search()  ‚îÇ           ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ\n",
    "‚îÇ                                                                 ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                             ‚îÇ\n",
    "‚îÇ  ‚îÇ   Episodic   ‚îÇ  ‚îÇ  Procedural  ‚îÇ                             ‚îÇ\n",
    "‚îÇ  ‚îÇ    Memory    ‚îÇ  ‚îÇ    Memory    ‚îÇ                             ‚îÇ\n",
    "‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ              ‚îÇ                             ‚îÇ\n",
    "‚îÇ  ‚îÇ  Few-shot    ‚îÇ  ‚îÇSelf-modifying‚îÇ                             ‚îÇ\n",
    "‚îÇ  ‚îÇ  examples    ‚îÇ  ‚îÇ   prompts    ‚îÇ                             ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                             ‚îÇ\n",
    "‚îÇ                                                                 ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### Key LangGraph Components\n",
    "\n",
    "| Component | Memory Type | Scope |\n",
    "|-----------|-------------|-------|\n",
    "| `MemorySaver` (Checkpointer) | Short-term | Within a single thread |\n",
    "| `InMemoryStore` | Long-term, Semantic, Episodic, Procedural | Across all threads |\n",
    "| `thread_id` | Short-term | Identifies unique conversations |\n",
    "| Namespaces | All store-based | Organizes memories by user/purpose |\n",
    "\n",
    "**Documentation:**\n",
    "- [CoALA Paper](https://arxiv.org/abs/2309.02427)\n",
    "- [LangGraph Memory Concepts](https://langchain-ai.github.io/langgraph/concepts/memory/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Short-Term Memory (MemorySaver, thread_id)\n",
    "\n",
    "**Short-term memory** maintains context within a single conversation thread. Think of it like your working memory during a phone call - you remember what was said earlier, but once the call ends, those details fade.\n",
    "\n",
    "In LangGraph, short-term memory is implemented through:\n",
    "- **Checkpointer**: Saves the graph state at each step\n",
    "- **thread_id**: Uniquely identifies each conversation\n",
    "\n",
    "### How It Works\n",
    "\n",
    "```\n",
    "Thread 1: \"Hi, I'm Alice\"          Thread 2: \"What's my name?\"\n",
    "     ‚îÇ                                   ‚îÇ\n",
    "     ‚ñº                                   ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ Checkpointer ‚îÇ                   ‚îÇ Checkpointer ‚îÇ\n",
    "‚îÇ  thread_1    ‚îÇ                   ‚îÇ  thread_2    ‚îÇ\n",
    "‚îÇ              ‚îÇ                   ‚îÇ              ‚îÇ\n",
    "‚îÇ [\"Hi Alice\"] ‚îÇ                   ‚îÇ [empty]      ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "     ‚îÇ                                   ‚îÇ\n",
    "     ‚ñº                                   ‚ñº\n",
    "\"Hi Alice!\"                        \"I don't know your name\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "# Define the state schema for our graph\n",
    "# The `add_messages` annotation tells LangGraph how to update the messages list\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "# Define our investment chatbot node\n",
    "def investment_chatbot(state: State):\n",
    "    \"\"\"Process the conversation and generate an investment-focused response.\"\"\"\n",
    "    system_prompt = SystemMessage(content=\"\"\"You are a friendly Investment Advisory Assistant. \n",
    "Help users with questions about Stone Ridge's investment philosophy, market outlook, \n",
    "portfolio strategy, and risk management.\n",
    "Be supportive and remember details the user shares about themselves.\"\"\")\n",
    "    \n",
    "    messages = [system_prompt] + state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Build the graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"chatbot\", investment_chatbot)\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# Compile with a checkpointer for short-term memory\n",
    "checkpointer = MemorySaver()\n",
    "investment_graph = builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "print(\"Investment chatbot compiled with short-term memory (checkpointing)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test short-term memory within a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"investment_thread_1\"}}\n",
    "\n",
    "# First message - introduce ourselves\n",
    "response = investment_graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Hi! My name is Alex and I want to understand Stone Ridge's investment approach.\")]},\n",
    "    config\n",
    ")\n",
    "print(\"User: Hi! My name is Alex and I want to understand Stone Ridge's investment approach.\")\n",
    "print(f\"Assistant: {response['messages'][-1].content}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second message - test if it remembers (same thread)\n",
    "response = investment_graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What's my name and what am I interested in learning about?\")]},\n",
    "    config  # Same config = same thread_id\n",
    ")\n",
    "print(\"User: What's my name and what am I interested in learning about?\")\n",
    "print(f\"Assistant: {response['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New thread - it won't remember Alex!\n",
    "different_config = {\"configurable\": {\"thread_id\": \"investment_thread_2\"}}\n",
    "\n",
    "response = investment_graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What's my name?\")]},\n",
    "    different_config  # Different thread_id = no memory of Alex\n",
    ")\n",
    "print(\"User (NEW thread): What's my name?\")\n",
    "print(f\"Assistant: {response['messages'][-1].content}\")\n",
    "print()\n",
    "print(\"Notice: The agent doesn't know our name because this is a new thread!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the state of thread 1\n",
    "state = investment_graph.get_state(config)\n",
    "print(f\"Thread 1 has {len(state.values['messages'])} messages:\")\n",
    "for msg in state.values['messages']:\n",
    "    role = \"User\" if isinstance(msg, HumanMessage) else \"Assistant\"\n",
    "    content = msg.content[:80] + \"...\" if len(msg.content) > 80 else msg.content\n",
    "    print(f\"  {role}: {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Long-Term Memory (InMemoryStore, namespaces)\n",
    "\n",
    "**Long-term memory** stores information across different conversation threads. This is like remembering that your friend prefers tea over coffee - you remember it every time you meet them, regardless of what you're currently discussing.\n",
    "\n",
    "In LangGraph, long-term memory uses:\n",
    "- **Store**: A persistent key-value store\n",
    "- **Namespaces**: Organize memories by user, application, or context\n",
    "\n",
    "### Key Difference from Short-Term Memory\n",
    "\n",
    "| Short-Term (Checkpointer) | Long-Term (Store) |\n",
    "|---------------------------|-------------------|\n",
    "| Scoped to a single thread | Shared across all threads |\n",
    "| Automatic (messages) | Explicit (you decide what to store) |\n",
    "| Conversation history | User preferences, facts, etc. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# Create a store for long-term memory\n",
    "store = InMemoryStore()\n",
    "\n",
    "# Namespaces organize memories - typically by user_id and category\n",
    "user_id = \"user_alex\"\n",
    "profile_namespace = (user_id, \"profile\")\n",
    "preferences_namespace = (user_id, \"preferences\")\n",
    "\n",
    "# Store Alex's investment profile\n",
    "store.put(profile_namespace, \"name\", {\"value\": \"Alex\"})\n",
    "store.put(profile_namespace, \"goals\", {\"primary\": \"long-term growth\", \"secondary\": \"income generation\"})\n",
    "store.put(profile_namespace, \"constraints\", {\"risk_tolerance\": \"moderate\", \"restrictions\": [\"no tobacco stocks\"], \"esg_preference\": True})\n",
    "store.put(profile_namespace, \"portfolio\", {\"size\": \"$500K\", \"horizon\": \"20 years\", \"current_allocation\": \"60/40 stocks/bonds\"})\n",
    "\n",
    "# Store Alex's preferences\n",
    "store.put(preferences_namespace, \"communication\", {\"style\": \"data-driven\", \"detail_level\": \"comprehensive\"})\n",
    "store.put(preferences_namespace, \"reporting\", {\"frequency\": \"quarterly\", \"preferred_metrics\": [\"CAGR\", \"Sharpe ratio\", \"max drawdown\"]})\n",
    "\n",
    "print(\"Stored Alex's profile and preferences in long-term memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve specific memories\n",
    "name = store.get(profile_namespace, \"name\")\n",
    "print(f\"Name: {name.value}\")\n",
    "\n",
    "goals = store.get(profile_namespace, \"goals\")\n",
    "print(f\"Goals: {goals.value}\")\n",
    "\n",
    "# List all memories in a namespace\n",
    "print(\"\\nAll profile items:\")\n",
    "for item in store.search(profile_namespace):\n",
    "    print(f\"  {item.key}: {item.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.base import BaseStore\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# Define state with user_id for personalization\n",
    "class PersonalizedState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    user_id: str\n",
    "\n",
    "\n",
    "def personalized_investment_chatbot(state: PersonalizedState, config: RunnableConfig, *, store: BaseStore):\n",
    "    \"\"\"An investment chatbot that uses long-term memory for personalization.\"\"\"\n",
    "    user_id = state[\"user_id\"]\n",
    "    profile_namespace = (user_id, \"profile\")\n",
    "    preferences_namespace = (user_id, \"preferences\")\n",
    "    \n",
    "    # Retrieve user profile from long-term memory\n",
    "    profile_items = list(store.search(profile_namespace))\n",
    "    pref_items = list(store.search(preferences_namespace))\n",
    "    \n",
    "    # Build context from profile\n",
    "    profile_text = \"\\n\".join([f\"- {p.key}: {p.value}\" for p in profile_items])\n",
    "    pref_text = \"\\n\".join([f\"- {p.key}: {p.value}\" for p in pref_items])\n",
    "    \n",
    "    system_msg = f\"\"\"You are an Investment Advisory Assistant. You know the following about this user:\n",
    "\n",
    "PROFILE:\n",
    "{profile_text if profile_text else 'No profile stored.'}\n",
    "\n",
    "PREFERENCES:\n",
    "{pref_text if pref_text else 'No preferences stored.'}\n",
    "\n",
    "Use this information to personalize your responses. Be supportive and helpful.\"\"\"\n",
    "    \n",
    "    messages = [SystemMessage(content=system_msg)] + state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Build the personalized graph\n",
    "builder2 = StateGraph(PersonalizedState)\n",
    "builder2.add_node(\"chatbot\", personalized_investment_chatbot)\n",
    "builder2.add_edge(START, \"chatbot\")\n",
    "builder2.add_edge(\"chatbot\", END)\n",
    "\n",
    "# Compile with BOTH checkpointer (short-term) AND store (long-term)\n",
    "personalized_graph = builder2.compile(\n",
    "    checkpointer=MemorySaver(),\n",
    "    store=store\n",
    ")\n",
    "\n",
    "print(\"Personalized graph compiled with both short-term and long-term memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the personalized chatbot - it knows Alex's profile!\n",
    "config = {\"configurable\": {\"thread_id\": \"personalized_thread_1\"}}\n",
    "\n",
    "response = personalized_graph.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"What investment strategy would you recommend for me?\")],\n",
    "        \"user_id\": \"user_alex\"\n",
    "    },\n",
    "    config\n",
    ")\n",
    "\n",
    "print(\"User: What investment strategy would you recommend for me?\")\n",
    "print(f\"Assistant: {response['messages'][-1].content}\")\n",
    "print()\n",
    "print(\"Notice: The agent knows about Alex's risk tolerance and portfolio without him mentioning it!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even in a NEW thread, it still knows Alex's profile\n",
    "# because long-term memory is cross-thread!\n",
    "\n",
    "new_config = {\"configurable\": {\"thread_id\": \"personalized_thread_2\"}}\n",
    "\n",
    "response = personalized_graph.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"Are there any risks I should be aware of given my portfolio?\")],\n",
    "        \"user_id\": \"user_alex\"\n",
    "    },\n",
    "    new_config\n",
    ")\n",
    "\n",
    "print(\"User (NEW thread): Are there any risks I should be aware of given my portfolio?\")\n",
    "print(f\"Assistant: {response['messages'][-1].content}\")\n",
    "print()\n",
    "print(\"Notice: Even in a new thread, the agent knows Alex's portfolio and constraints!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Message Trimming & Context Management\n",
    "\n",
    "Long conversations can exceed the LLM's context window. LangGraph provides utilities to manage message history:\n",
    "\n",
    "- **`trim_messages`**: Keeps only recent messages up to a token limit\n",
    "- **Summarization**: Compress older messages into summaries\n",
    "\n",
    "### Why Trim Even with 128K Context?\n",
    "\n",
    "Even with large context windows:\n",
    "1. **Cost**: More tokens = higher API costs\n",
    "2. **Latency**: Larger contexts take longer to process\n",
    "3. **Quality**: Models can struggle with \"lost in the middle\" - important info buried in long contexts\n",
    "4. **Relevance**: Old messages may not be relevant to current query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import trim_messages\n",
    "\n",
    "# Create a trimmer that keeps only recent messages\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=500,  # Keep messages up to this token count\n",
    "    strategy=\"last\",  # Keep the most recent messages\n",
    "    token_counter=llm,  # Use the LLM to count tokens\n",
    "    include_system=True,  # Always keep system messages\n",
    "    allow_partial=False,  # Don't cut messages in half\n",
    ")\n",
    "\n",
    "# Example: Create a long conversation\n",
    "long_conversation = [\n",
    "    SystemMessage(content=\"You are an investment advisory assistant.\"),\n",
    "    HumanMessage(content=\"I want to improve my portfolio returns.\"),\n",
    "    AIMessage(content=\"Great goal! Let's start with your current allocation. What does your portfolio look like?\"),\n",
    "    HumanMessage(content=\"I have about 60% stocks and 40% bonds.\"),\n",
    "    AIMessage(content=\"That's a balanced allocation. For higher returns, you might consider increasing equity exposure or adding alternative investments.\"),\n",
    "    HumanMessage(content=\"What about international diversification?\"),\n",
    "    AIMessage(content=\"International exposure can reduce risk through diversification. Consider allocating 20-30% to international developed and emerging markets.\"),\n",
    "    HumanMessage(content=\"And alternative investments?\"),\n",
    "    AIMessage(content=\"Alternatives like reinsurance, real estate, and commodities can provide uncorrelated returns and enhance portfolio efficiency.\"),\n",
    "    HumanMessage(content=\"What's the most important change I should make first?\"),\n",
    "]\n",
    "\n",
    "# Trim to fit context window\n",
    "trimmed = trimmer.invoke(long_conversation)\n",
    "print(f\"Original: {len(long_conversation)} messages\")\n",
    "print(f\"Trimmed: {len(trimmed)} messages\")\n",
    "print(\"\\nTrimmed conversation:\")\n",
    "for msg in trimmed:\n",
    "    role = type(msg).__name__.replace(\"Message\", \"\")\n",
    "    content = msg.content[:60] + \"...\" if len(msg.content) > 60 else msg.content\n",
    "    print(f\"  {role}: {content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarization approach for longer conversations\n",
    "\n",
    "def summarize_conversation(messages: list, max_messages: int = 6) -> list:\n",
    "    \"\"\"Summarize older messages to manage context length.\"\"\"\n",
    "    if len(messages) <= max_messages:\n",
    "        return messages\n",
    "    \n",
    "    # Keep the system message and last few messages\n",
    "    system_msg = messages[0] if isinstance(messages[0], SystemMessage) else None\n",
    "    content_messages = messages[1:] if system_msg else messages\n",
    "    \n",
    "    if len(content_messages) <= max_messages:\n",
    "        return messages\n",
    "    \n",
    "    old_messages = content_messages[:-max_messages+1]\n",
    "    recent_messages = content_messages[-max_messages+1:]\n",
    "    \n",
    "    # Summarize old messages\n",
    "    summary_prompt = f\"\"\"Summarize this conversation in 2-3 sentences, \n",
    "capturing key investment topics discussed and any important user information:\n",
    "\n",
    "{chr(10).join([f'{type(m).__name__}: {m.content[:200]}' for m in old_messages])}\"\"\"\n",
    "    \n",
    "    summary = llm.invoke(summary_prompt)\n",
    "    \n",
    "    # Return: system + summary + recent messages\n",
    "    result = []\n",
    "    if system_msg:\n",
    "        result.append(system_msg)\n",
    "    result.append(SystemMessage(content=f\"[Previous conversation summary: {summary.content}]\"))\n",
    "    result.extend(recent_messages)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Test summarization\n",
    "summarized = summarize_conversation(long_conversation, max_messages=4)\n",
    "print(f\"Summarized: {len(summarized)} messages\")\n",
    "print(\"\\nSummarized conversation:\")\n",
    "for msg in summarized:\n",
    "    role = type(msg).__name__.replace(\"Message\", \"\")\n",
    "    content = msg.content[:80] + \"...\" if len(msg.content) > 80 else msg.content\n",
    "    print(f\"  {role}: {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚ùì Question #1:\n",
    "\n",
    "What are the trade-offs between **short-term memory** (checkpointer) vs **long-term memory** (store)? When should investment data move from short-term to long-term? Consider:\n",
    "- What information should persist across sessions?\n",
    "- What are the compliance implications?\n",
    "- How would you decide what to promote from short-term to long-term?\n",
    "\n",
    "##### Answer:\n",
    "\n",
    "**Trade-offs:**\n",
    "\n",
    "**Short-term memory (Checkpointer):**\n",
    "- ‚úÖ Automatic management of conversation history\n",
    "- ‚úÖ Scoped to individual threads - easier privacy control\n",
    "- ‚úÖ Natural for transient consultation context\n",
    "- ‚ùå Lost when thread ends or is manually cleared\n",
    "- ‚ùå Not queryable across conversations\n",
    "- ‚ùå Storage grows with conversation length\n",
    "\n",
    "**Long-term memory (Store):**\n",
    "- ‚úÖ Persists across all sessions and threads\n",
    "- ‚úÖ Queryable and searchable across user history\n",
    "- ‚úÖ Enables personalization and continuity\n",
    "- ‚ùå Requires explicit decisions on what to store\n",
    "- ‚ùå Storage and privacy management overhead\n",
    "- ‚ùå Potential for stale or conflicting data\n",
    "\n",
    "**When to move data from short-term to long-term:**\n",
    "\n",
    "1. **User Profile Information** ‚Üí Long-term\n",
    "   - Risk tolerance, investment horizon, portfolio constraints\n",
    "   - These are stable attributes that should persist across sessions\n",
    "   \n",
    "2. **Investment Goals & Constraints** ‚Üí Long-term\n",
    "   - Primary/secondary goals, ESG preferences, sector restrictions\n",
    "   - Critical for consistent advice across consultations\n",
    "\n",
    "3. **Important Decisions Made** ‚Üí Long-term (Episodic)\n",
    "   - Asset allocation changes, rebalancing decisions\n",
    "   - Creates audit trail and learning opportunities\n",
    "\n",
    "4. **Transient Market Discussion** ‚Üí Short-term only\n",
    "   - Current market commentary, specific price discussions\n",
    "   - Time-sensitive and quickly becomes outdated\n",
    "\n",
    "**Compliance Implications:**\n",
    "\n",
    "- **Recordkeeping**: Financial regulations (e.g., SEC, FINRA) require maintaining records of investment advice given\n",
    "- **Data Retention**: Must balance retention requirements with privacy laws (GDPR, CCPA)\n",
    "- **Audit Trail**: Long-term memory should include timestamps and versioning for compliance review\n",
    "- **Privacy**: User PII should be encrypted and access-controlled in long-term storage\n",
    "- **Right to Erasure**: Must support deletion of user data upon request\n",
    "\n",
    "**Decision Framework for Promotion:**\n",
    "\n",
    "```python\n",
    "def should_promote_to_long_term(data_type: str, user_action: str) -> bool:\n",
    "    # Explicit user confirmations\n",
    "    if user_action in [\"confirmed_profile\", \"set_goal\", \"made_decision\"]:\n",
    "        return True\n",
    "    \n",
    "    # Critical constraints that affect advice\n",
    "    if data_type in [\"risk_tolerance\", \"investment_restrictions\", \"portfolio_size\"]:\n",
    "        return True\n",
    "    \n",
    "    # Successful outcomes worth remembering\n",
    "    if data_type == \"advisory_episode\" and user_feedback == \"positive\":\n",
    "        return True\n",
    "    \n",
    "    # Transient data stays in short-term\n",
    "    if data_type in [\"market_commentary\", \"casual_question\"]:\n",
    "        return False\n",
    "    \n",
    "    return False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùì Question #2:\n",
    "\n",
    "Why use message trimming with a 128K context window when the Stone Ridge investor letter is relatively small? What should **always** be preserved when trimming an investment consultation?\n",
    "\n",
    "Consider:\n",
    "- The \"lost in the middle\" phenomenon\n",
    "- Cost and latency implications\n",
    "- What user information is critical for safety (risk tolerance, constraints, etc.)\n",
    "\n",
    "##### Answer:\n",
    "\n",
    "**Why trim even with large context windows:**\n",
    "\n",
    "1. **\"Lost in the Middle\" Phenomenon**\n",
    "   - Research shows LLMs struggle to use information in the middle of very long contexts\n",
    "   - Important details can be overlooked when buried in extensive conversation history\n",
    "   - Shorter, focused context improves retrieval accuracy and response relevance\n",
    "\n",
    "2. **Cost Optimization**\n",
    "   - GPT-4 pricing: ~$5/1M input tokens, $15/1M output tokens\n",
    "   - A 50-message conversation could be 20K+ tokens\n",
    "   - Trimming to 500-2000 tokens per request saves 90%+ on costs\n",
    "   - Over thousands of users and consultations, savings compound significantly\n",
    "\n",
    "3. **Latency Reduction**\n",
    "   - First-token latency matters for user experience\n",
    "   - Shorter contexts = faster responses = better UX\n",
    "\n",
    "4. **Quality > Quantity**\n",
    "   - Recent context is usually most relevant\n",
    "   - Long-ago messages may contain outdated or conflicting information\n",
    "   - Focused context helps the model stay on topic\n",
    "\n",
    "**What must ALWAYS be preserved:**\n",
    "\n",
    "1. **System Instructions** (`include_system=True`)\n",
    "   - Core advisory guidelines and compliance requirements\n",
    "   - Procedural memory (self-improving instructions)\n",
    "   - Non-negotiable behavior boundaries\n",
    "\n",
    "2. **User Risk Profile & Constraints** (via long-term memory)\n",
    "   - Risk tolerance level (conservative/moderate/aggressive)\n",
    "   - Investment restrictions (e.g., \"no tobacco stocks\", \"ESG only\")\n",
    "   - Legal constraints (accredited investor status, jurisdiction)\n",
    "   - Portfolio size and investment horizon\n",
    "   - **Why**: Giving inappropriate advice for risk profile is dangerous\n",
    "\n",
    "3. **Previously Established Goals & Context**\n",
    "   - Investment objectives stated in current thread\n",
    "   - Important decisions made in current consultation\n",
    "   - **Why**: Contradicting previous statements in same conversation erodes trust\n",
    "\n",
    "4. **Compliance-Critical Information**\n",
    "   - Disclaimers that have been provided\n",
    "   - Acknowledgment that advice is not a guarantee\n",
    "   - Regulatory disclosures\n",
    "\n",
    "**Trimming Strategy:**\n",
    "\n",
    "```python\n",
    "def safe_investment_trimmer(messages, max_tokens=2000):\n",
    "    # Extract critical information before trimming\n",
    "    risk_profile = extract_from_long_term_memory()\n",
    "    current_goals = extract_goals_from_conversation(messages)\n",
    "    \n",
    "    # Build system message with critical context\n",
    "    system_msg = f\"\"\"Investment Advisory Assistant\n",
    "    \n",
    "    USER PROFILE (ALWAYS REMEMBER):\n",
    "    - Risk Tolerance: {risk_profile.risk_tolerance}\n",
    "    - Investment Restrictions: {risk_profile.restrictions}\n",
    "    - Portfolio Size: {risk_profile.portfolio_size}\n",
    "    - Investment Horizon: {risk_profile.horizon}\n",
    "    \n",
    "    CURRENT SESSION GOALS:\n",
    "    {current_goals}\n",
    "    \n",
    "    [Standard compliance disclaimers...]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Trim conversation but keep system message\n",
    "    trimmed = trim_messages(\n",
    "        messages,\n",
    "        max_tokens=max_tokens,\n",
    "        include_system=True,\n",
    "        strategy=\"last\"\n",
    "    )\n",
    "    \n",
    "    return [SystemMessage(content=system_msg)] + trimmed[1:]\n",
    "```\n",
    "\n",
    "**Alternative: Semantic Summarization**\n",
    "- Instead of dropping old messages entirely, summarize them\n",
    "- Preserves key decisions and context while reducing tokens\n",
    "- Example: \"Earlier in conversation: user expressed concern about market volatility and preference for defensive positioning\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üèóÔ∏è Activity #1: Store & Retrieve User Investment Profile\n",
    "\n",
    "Build a complete investment profile system that:\n",
    "1. Defines an investment profile schema (name, risk tolerance, portfolio size, investment horizon, restrictions, goals)\n",
    "2. Creates functions to store and retrieve profile data\n",
    "3. Builds a personalized investment agent that uses the profile\n",
    "4. Tests that different users get different advice\n",
    "\n",
    "### Requirements:\n",
    "- Define at least 5 profile attributes\n",
    "- Support multiple users with different profiles\n",
    "- Agent should reference profile data in responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Optional, List\n",
    "from datetime import datetime\n",
    "\n",
    "class InvestmentProfile:\n",
    "    \"\"\"Schema for user investment profile.\"\"\"\n",
    "    name: str\n",
    "    risk_tolerance: Literal[\"conservative\", \"moderate\", \"aggressive\"]\n",
    "    portfolio_size: str\n",
    "    investment_horizon: str  # e.g., \"5 years\", \"20 years\", \"indefinite\"\n",
    "    restrictions: List[str]  # e.g., [\"no tobacco\", \"no weapons\"]\n",
    "    goals: dict  # {\"primary\": \"...\", \"secondary\": \"...\"}\n",
    "    preferred_asset_classes: List[str]\n",
    "    esg_preference: bool\n",
    "    accredited_investor: bool\n",
    "    annual_income: Optional[str]\n",
    "\n",
    "\n",
    "def store_investment_profile(store, user_id: str, profile: dict):\n",
    "    \"\"\"Store a user's investment profile.\"\"\"\n",
    "    namespace = (user_id, \"profile\")\n",
    "    \n",
    "    # Store each profile attribute separately for easier querying\n",
    "    for key, value in profile.items():\n",
    "        store.put(namespace, key, {\"value\": value, \"updated_at\": datetime.now().isoformat()})\n",
    "    \n",
    "    print(f\"Stored investment profile for {user_id}\")\n",
    "\n",
    "\n",
    "def get_investment_profile(store, user_id: str) -> dict:\n",
    "    \"\"\"Retrieve a user's investment profile.\"\"\"\n",
    "    namespace = (user_id, \"profile\")\n",
    "    \n",
    "    # Retrieve all profile items\n",
    "    items = list(store.search(namespace))\n",
    "    \n",
    "    if not items:\n",
    "        return {}\n",
    "    \n",
    "    # Reconstruct profile dictionary\n",
    "    profile = {}\n",
    "    for item in items:\n",
    "        profile[item.key] = item.value[\"value\"]\n",
    "    \n",
    "    return profile\n",
    "\n",
    "\n",
    "store_activity1 = InMemoryStore()\n",
    "\n",
    "# Profile 1: Conservative retiree\n",
    "profile_sarah = {\n",
    "    \"name\": \"Sarah Chen\",\n",
    "    \"risk_tolerance\": \"conservative\",\n",
    "    \"portfolio_size\": \"$2.5M\",\n",
    "    \"investment_horizon\": \"indefinite (retired)\",\n",
    "    \"restrictions\": [\"no tobacco\", \"no weapons\", \"ESG preferred\"],\n",
    "    \"goals\": {\n",
    "        \"primary\": \"income generation and capital preservation\",\n",
    "        \"secondary\": \"modest growth to outpace inflation\"\n",
    "    },\n",
    "    \"preferred_asset_classes\": [\"bonds\", \"dividend stocks\", \"REITs\"],\n",
    "    \"esg_preference\": True,\n",
    "    \"accredited_investor\": True,\n",
    "    \"annual_income\": \"$150K (from portfolio)\"\n",
    "}\n",
    "\n",
    "# Profile 2: Aggressive young professional\n",
    "profile_david = {\n",
    "    \"name\": \"David Kim\",\n",
    "    \"risk_tolerance\": \"aggressive\",\n",
    "    \"portfolio_size\": \"$200K\",\n",
    "    \"investment_horizon\": \"30 years\",\n",
    "    \"restrictions\": [],\n",
    "    \"goals\": {\n",
    "        \"primary\": \"maximize long-term capital appreciation\",\n",
    "        \"secondary\": \"explore alternative investments\"\n",
    "    },\n",
    "    \"preferred_asset_classes\": [\"growth stocks\", \"crypto\", \"venture capital\", \"alternatives\"],\n",
    "    \"esg_preference\": False,\n",
    "    \"accredited_investor\": False,\n",
    "    \"annual_income\": \"$180K (salary)\"\n",
    "}\n",
    "\n",
    "store_investment_profile(store_activity1, \"user_sarah\", profile_sarah)\n",
    "store_investment_profile(store_activity1, \"user_david\", profile_david)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Created two user profiles:\")\n",
    "print(f\"1. Sarah Chen - Conservative retiree\")\n",
    "print(f\"2. David Kim - Aggressive young professional\")\n",
    "\n",
    "\n",
    "class ProfileState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    user_id: str\n",
    "\n",
    "\n",
    "def profile_based_advisor(state: ProfileState, config: RunnableConfig, *, store: BaseStore):\n",
    "    \"\"\"Investment advisor that personalizes based on user profile.\"\"\"\n",
    "    user_id = state[\"user_id\"]\n",
    "    profile = get_investment_profile(store, user_id)\n",
    "    \n",
    "    if not profile:\n",
    "        system_msg = \"You are an Investment Advisory Assistant. Ask the user about their investment profile first.\"\n",
    "    else:\n",
    "        # Build detailed profile context\n",
    "        profile_text = f\"\"\"\n",
    "User: {profile.get('name', 'Unknown')}\n",
    "Risk Tolerance: {profile.get('risk_tolerance', 'Unknown')}\n",
    "Portfolio Size: {profile.get('portfolio_size', 'Unknown')}\n",
    "Investment Horizon: {profile.get('investment_horizon', 'Unknown')}\n",
    "Investment Goals: {profile.get('goals', {})}\n",
    "Restrictions: {', '.join(profile.get('restrictions', [])) if profile.get('restrictions') else 'None'}\n",
    "Preferred Asset Classes: {', '.join(profile.get('preferred_asset_classes', []))}\n",
    "ESG Preference: {'Yes' if profile.get('esg_preference') else 'No'}\n",
    "Accredited Investor: {'Yes' if profile.get('accredited_investor') else 'No'}\n",
    "\"\"\"\n",
    "        \n",
    "        system_msg = f\"\"\"You are an Investment Advisory Assistant. You have access to this user's profile:\n",
    "\n",
    "{profile_text}\n",
    "\n",
    "IMPORTANT GUIDELINES:\n",
    "- Tailor ALL recommendations to their risk tolerance level\n",
    "- Respect their investment restrictions absolutely\n",
    "- Align advice with their stated goals and time horizon\n",
    "- Only suggest accredited-investor-only investments if they qualify\n",
    "- If they prefer ESG, prioritize sustainable investment options\n",
    "- Reference their preferred asset classes when making suggestions\n",
    "\n",
    "Always provide personalized, profile-appropriate advice.\"\"\"\n",
    "    \n",
    "    messages = [SystemMessage(content=system_msg)] + state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Build the graph\n",
    "builder_activity1 = StateGraph(ProfileState)\n",
    "builder_activity1.add_node(\"advisor\", profile_based_advisor)\n",
    "builder_activity1.add_edge(START, \"advisor\")\n",
    "builder_activity1.add_edge(\"advisor\", END)\n",
    "\n",
    "profile_advisor_graph = builder_activity1.compile(\n",
    "    checkpointer=MemorySaver(),\n",
    "    store=store_activity1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Profile-based advisor agent ready!\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Testing with Sarah (conservative retiree)...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "response_sarah = profile_advisor_graph.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"I'm interested in alternative investments. What would you recommend for me?\")],\n",
    "        \"user_id\": \"user_sarah\"\n",
    "    },\n",
    "    {\"configurable\": {\"thread_id\": \"sarah_thread_1\"}}\n",
    ")\n",
    "\n",
    "print(f\"\\nSarah asks: I'm interested in alternative investments. What would you recommend for me?\")\n",
    "print(f\"\\nAdvisor response:\\n{response_sarah['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Testing with David (aggressive young professional)...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "response_david = profile_advisor_graph.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"I'm interested in alternative investments. What would you recommend for me?\")],\n",
    "        \"user_id\": \"user_david\"\n",
    "    },\n",
    "    {\"configurable\": {\"thread_id\": \"david_thread_1\"}}\n",
    ")\n",
    "\n",
    "print(f\"\\nDavid asks: I'm interested in alternative investments. What would you recommend for me?\")\n",
    "print(f\"\\nAdvisor response:\\n{response_david['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON:\")\n",
    "print(\"Notice how the SAME question gets DIFFERENT advice based on:\")\n",
    "print(\"- Sarah: Conservative, retired, ESG-focused ‚Üí safer alternatives\")\n",
    "print(\"- David: Aggressive, 30-year horizon ‚Üí higher-risk alternatives\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ü§ù Breakout Room #2\n",
    "## Advanced Memory & Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Semantic Memory (Embeddings + Search)\n",
    "\n",
    "**Semantic memory** stores facts and retrieves them based on *meaning* rather than exact matches. This is like how you might remember \"that fund with the great risk-adjusted returns\" even if you can't remember its exact name.\n",
    "\n",
    "In LangGraph, semantic memory uses:\n",
    "- **Store with embeddings**: Converts text to vectors for similarity search\n",
    "- **`store.search()`**: Finds relevant memories by semantic similarity\n",
    "\n",
    "### How It Works\n",
    "\n",
    "```\n",
    "User asks: \"What helps with portfolio diversification?\"\n",
    "         ‚Üì\n",
    "Query embedded ‚Üí [0.2, 0.8, 0.1, ...]\n",
    "         ‚Üì\n",
    "Compare with stored investment facts:\n",
    "  - \"Uncorrelated assets reduce portfolio risk\" ‚Üí 0.92 similarity ‚úì\n",
    "  - \"Rebalancing maintains target allocations\" ‚Üí 0.35 similarity\n",
    "         ‚Üì\n",
    "Return: \"Uncorrelated assets reduce portfolio risk\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Create embeddings model\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Create a store with semantic search enabled\n",
    "semantic_store = InMemoryStore(\n",
    "    index={\n",
    "        \"embed\": embeddings,\n",
    "        \"dims\": 1536,  # Dimension of text-embedding-3-small\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Semantic memory store created with embedding support\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store various investment facts as semantic memories\n",
    "namespace = (\"investment\", \"facts\")\n",
    "\n",
    "investment_facts = [\n",
    "    (\"fact_1\", {\"text\": \"Diversification across uncorrelated assets can reduce portfolio risk without sacrificing returns\"}),\n",
    "    (\"fact_2\", {\"text\": \"Stone Ridge focuses on alternative risk premiums including reinsurance and longevity risk\"}),\n",
    "    (\"fact_3\", {\"text\": \"Tail risk hedging provides insurance against extreme market downturns\"}),\n",
    "    (\"fact_4\", {\"text\": \"A long-term investment horizon allows investors to capture illiquidity premiums\"}),\n",
    "    (\"fact_5\", {\"text\": \"Factor investing targets specific drivers of return such as value, momentum, and quality\"}),\n",
    "    (\"fact_6\", {\"text\": \"Rebalancing portfolios periodically helps maintain target risk levels\"}),\n",
    "    (\"fact_7\", {\"text\": \"Alternative investments like reinsurance have low correlation with traditional stock and bond markets\"}),\n",
    "    (\"fact_8\", {\"text\": \"Systematic risk management frameworks help identify and mitigate portfolio vulnerabilities\"}),\n",
    "]\n",
    "\n",
    "for key, value in investment_facts:\n",
    "    semantic_store.put(namespace, key, value)\n",
    "\n",
    "print(f\"Stored {len(investment_facts)} investment facts in semantic memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search semantically - notice we don't need exact matches!\n",
    "\n",
    "queries = [\n",
    "    \"How can I protect my portfolio from a market crash?\",\n",
    "    \"What alternative investments should I consider?\",\n",
    "    \"How should I think about risk in my portfolio?\",\n",
    "    \"What is Stone Ridge's investment approach?\",\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    results = semantic_store.search(namespace, query=query, limit=2)\n",
    "    for r in results:\n",
    "        print(f\"   {r.value['text']} (score: {r.score:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Building Semantic Investment Knowledge Base\n",
    "\n",
    "Let's load the Stone Ridge 2025 Investor Letter and create a semantic knowledge base that our agent can search.\n",
    "\n",
    "This is similar to RAG from Module 4, but now using LangGraph's Store API instead of a separate vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load and chunk the investment document\n",
    "loader = PyMuPDFLoader(\"data/Stone Ridge 2025 Investor Letter.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Loaded and split into {len(chunks)} chunks\")\n",
    "print(f\"\\nSample chunk:\\n{chunks[0].page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store chunks in semantic memory\n",
    "knowledge_namespace = (\"investment\", \"knowledge\")\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    semantic_store.put(\n",
    "        knowledge_namespace,\n",
    "        f\"chunk_{i}\",\n",
    "        {\"text\": chunk.page_content, \"source\": \"Stone Ridge 2025 Investor Letter.pdf\"}\n",
    "    )\n",
    "\n",
    "print(f\"Stored {len(chunks)} chunks in semantic knowledge base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a semantic search investment chatbot\n",
    "\n",
    "class SemanticState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    user_id: str\n",
    "\n",
    "\n",
    "def semantic_investment_chatbot(state: SemanticState, config: RunnableConfig, *, store: BaseStore):\n",
    "    \"\"\"An investment chatbot that retrieves relevant facts using semantic search.\"\"\"\n",
    "    user_message = state[\"messages\"][-1].content\n",
    "    \n",
    "    # Search for relevant knowledge\n",
    "    knowledge_results = store.search(\n",
    "        (\"investment\", \"knowledge\"),\n",
    "        query=user_message,\n",
    "        limit=3\n",
    "    )\n",
    "    \n",
    "    # Build context from retrieved knowledge\n",
    "    if knowledge_results:\n",
    "        knowledge_text = \"\\n\\n\".join([f\"- {r.value['text']}\" for r in knowledge_results])\n",
    "        system_msg = f\"\"\"You are an Investment Advisory Assistant with access to the Stone Ridge investor letter knowledge base.\n",
    "\n",
    "Relevant information from your knowledge base:\n",
    "{knowledge_text}\n",
    "\n",
    "Use this information to answer the user's question. If the information doesn't directly answer their question, use your general knowledge but mention what you found.\"\"\"\n",
    "    else:\n",
    "        system_msg = \"You are an Investment Advisory Assistant. Answer investment questions helpfully.\"\n",
    "    \n",
    "    messages = [SystemMessage(content=system_msg)] + state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Build and compile\n",
    "builder3 = StateGraph(SemanticState)\n",
    "builder3.add_node(\"chatbot\", semantic_investment_chatbot)\n",
    "builder3.add_edge(START, \"chatbot\")\n",
    "builder3.add_edge(\"chatbot\", END)\n",
    "\n",
    "semantic_graph = builder3.compile(\n",
    "    checkpointer=MemorySaver(),\n",
    "    store=semantic_store\n",
    ")\n",
    "\n",
    "print(\"Semantic investment chatbot ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test semantic retrieval\n",
    "config = {\"configurable\": {\"thread_id\": \"semantic_thread_1\"}}\n",
    "\n",
    "questions = [\n",
    "    \"What is Stone Ridge's view on the current market environment?\",\n",
    "    \"How does Stone Ridge approach risk management?\",\n",
    "    \"What is Stone Ridge's investment philosophy?\",\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    response = semantic_graph.invoke(\n",
    "        {\"messages\": [HumanMessage(content=q)], \"user_id\": \"test_user\"},\n",
    "        config\n",
    "    )\n",
    "    print(f\"\\nUser: {q}\")\n",
    "    print(f\"Assistant: {response['messages'][-1].content[:500]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Episodic Memory (Few-Shot Learning)\n",
    "\n",
    "**Episodic memory** stores past experiences and uses them as examples for future tasks. In humans, this is like remembering the first time you provided a successful investment recommendation and using that experience to guide future interactions.\n",
    "\n",
    "For AI agents, episodic memory is often implemented as **few-shot examples** - showing the model examples of correct behavior so it can learn patterns.\n",
    "\n",
    "### The CoALA Framework Perspective\n",
    "\n",
    "> \"Facts can be written to semantic memory, whereas **experiences** can be written to episodic memory.\"\n",
    "\n",
    "Key insight: Sometimes it's easier to **show** than **tell**. LLMs learn well from examples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create episodic memory with past successful interactions\n",
    "episodic_namespace = (\"agent\", \"episodes\")\n",
    "\n",
    "successful_episodes = [\n",
    "    {\n",
    "        \"situation\": \"User asked about portfolio diversification with concentrated holdings\",\n",
    "        \"input\": \"I have most of my portfolio in tech stocks. How should I diversify?\",\n",
    "        \"output\": \"\"\"For a concentrated tech portfolio, I'd recommend diversifying across several dimensions:\n",
    "\n",
    "1. **Asset classes** - Add bonds, real estate (REITs), and alternatives\n",
    "2. **Geographies** - Include international developed and emerging markets\n",
    "3. **Sectors** - Shift allocation toward healthcare, consumer staples, and industrials\n",
    "4. **Alternative risk premiums** - Consider reinsurance or longevity-linked investments\n",
    "\n",
    "Start by gradually rebalancing 5-10% per quarter to avoid tax impacts. Would you like a specific rebalancing plan?\"\"\",\n",
    "        \"feedback\": \"User appreciated the structured approach and specific action items\"\n",
    "    },\n",
    "    {\n",
    "        \"situation\": \"User concerned about market downturn impact on retirement portfolio\",\n",
    "        \"input\": \"I'm 10 years from retirement and worried about a market crash. What should I do?\",\n",
    "        \"output\": \"\"\"Market timing is difficult, but there are proven strategies to protect near-retirement portfolios:\n",
    "\n",
    "**Risk reduction:**\n",
    "- Gradually shift to a more conservative allocation (e.g., 50/50 stocks/bonds)\n",
    "- Consider tail risk hedging for catastrophic downside protection\n",
    "\n",
    "**Income stability:**\n",
    "- Build a 2-3 year cash buffer for living expenses\n",
    "- Add dividend-paying stocks and investment-grade bonds\n",
    "\n",
    "**Stay invested:**\n",
    "- Keep some equity exposure for growth to combat inflation\n",
    "- Focus on quality companies with strong balance sheets\n",
    "\n",
    "Which aspect would you like to explore in more detail?\"\"\",\n",
    "        \"feedback\": \"User found the balanced approach reassuring and actionable\"\n",
    "    },\n",
    "    {\n",
    "        \"situation\": \"User asking about alternative investments\",\n",
    "        \"input\": \"What are alternative investments and should I have them in my portfolio?\",\n",
    "        \"output\": \"\"\"Alternative investments are assets beyond traditional stocks and bonds. They can add diversification and unique return sources:\n",
    "\n",
    "**Common alternatives:**\n",
    "- Real estate (REITs, direct property)\n",
    "- Private equity and venture capital\n",
    "- Hedge funds and managed futures\n",
    "- Reinsurance and catastrophe bonds\n",
    "- Commodities and natural resources\n",
    "\n",
    "**Benefits:**\n",
    "- Low correlation with traditional markets\n",
    "- Access to different risk premiums\n",
    "- Potential for higher risk-adjusted returns\n",
    "\n",
    "**Considerations:**\n",
    "- Often less liquid than public markets\n",
    "- May require higher minimum investments\n",
    "- Due diligence is critical\n",
    "\n",
    "A typical allocation might be 10-20% of your portfolio. What's your current portfolio size and investment horizon?\"\"\",\n",
    "        \"feedback\": \"User valued the comprehensive overview without being overwhelming\"\n",
    "    },\n",
    "]\n",
    "\n",
    "for i, episode in enumerate(successful_episodes):\n",
    "    semantic_store.put(\n",
    "        episodic_namespace,\n",
    "        f\"episode_{i}\",\n",
    "        {\n",
    "            \"text\": episode[\"situation\"],  # Used for semantic search\n",
    "            **episode\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(f\"Stored {len(successful_episodes)} episodic memories (past successful interactions)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpisodicState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "def episodic_investment_chatbot(state: EpisodicState, config: RunnableConfig, *, store: BaseStore):\n",
    "    \"\"\"A chatbot that learns from past successful interactions.\"\"\"\n",
    "    user_question = state[\"messages\"][-1].content\n",
    "    \n",
    "    # Search for similar past experiences\n",
    "    similar_episodes = store.search(\n",
    "        (\"agent\", \"episodes\"),\n",
    "        query=user_question,\n",
    "        limit=1\n",
    "    )\n",
    "    \n",
    "    # Build few-shot examples from past episodes\n",
    "    if similar_episodes:\n",
    "        episode = similar_episodes[0].value\n",
    "        few_shot_example = f\"\"\"Here's an example of a similar investment question I handled well:\n",
    "\n",
    "User asked: {episode['input']}\n",
    "\n",
    "My response was:\n",
    "{episode['output']}\n",
    "\n",
    "The user feedback was: {episode['feedback']}\n",
    "\n",
    "Use this as inspiration for the style, structure, and tone of your response, but tailor it to the current question.\"\"\"\n",
    "        \n",
    "        system_msg = f\"\"\"You are an Investment Advisory Assistant. Learn from your past successes:\n",
    "\n",
    "{few_shot_example}\"\"\"\n",
    "    else:\n",
    "        system_msg = \"You are an Investment Advisory Assistant. Be helpful, specific, and supportive.\"\n",
    "    \n",
    "    messages = [SystemMessage(content=system_msg)] + state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Build the episodic memory graph\n",
    "builder4 = StateGraph(EpisodicState)\n",
    "builder4.add_node(\"chatbot\", episodic_investment_chatbot)\n",
    "builder4.add_edge(START, \"chatbot\")\n",
    "builder4.add_edge(\"chatbot\", END)\n",
    "\n",
    "episodic_graph = builder4.compile(\n",
    "    checkpointer=MemorySaver(),\n",
    "    store=semantic_store\n",
    ")\n",
    "\n",
    "print(\"Episodic memory chatbot ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test episodic memory - similar question to stored episode\n",
    "config = {\"configurable\": {\"thread_id\": \"episodic_thread_1\"}}\n",
    "\n",
    "response = episodic_graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"I'm thinking about adding some alternative investments to my portfolio. What should I consider?\")]},\n",
    "    config\n",
    ")\n",
    "\n",
    "print(\"User: I'm thinking about adding some alternative investments to my portfolio. What should I consider?\")\n",
    "print(f\"\\nAssistant: {response['messages'][-1].content}\")\n",
    "print(\"\\nNotice: The response structure mirrors the successful alternatives episode!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9: Procedural Memory (Self-Improving Agent)\n",
    "\n",
    "**Procedural memory** stores the rules and instructions that guide behavior. In humans, this is like knowing *how* to give good advice - it's internalized knowledge about performing tasks.\n",
    "\n",
    "For AI agents, procedural memory often means **self-modifying prompts**. The agent can:\n",
    "1. Store its current instructions in the memory store\n",
    "2. Reflect on feedback from interactions\n",
    "3. Update its own instructions to improve\n",
    "\n",
    "### The Reflection Pattern\n",
    "\n",
    "```\n",
    "User feedback: \"Your advice is too long and complicated\"\n",
    "         ‚Üì\n",
    "Agent reflects on current instructions\n",
    "         ‚Üì\n",
    "Agent updates instructions: \"Keep advice concise and actionable\"\n",
    "         ‚Üì\n",
    "Future responses use updated instructions\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize procedural memory with base instructions\n",
    "procedural_namespace = (\"agent\", \"instructions\")\n",
    "\n",
    "initial_instructions = \"\"\"You are an Investment Advisory Assistant.\n",
    "\n",
    "Guidelines:\n",
    "- Be objective and data-driven in your analysis\n",
    "- Provide evidence-based investment information\n",
    "- Ask clarifying questions about risk tolerance and investment goals\n",
    "- Present balanced perspectives on investment decisions\n",
    "- Always note that past performance doesn't guarantee future results\"\"\"\n",
    "\n",
    "semantic_store.put(\n",
    "    procedural_namespace,\n",
    "    \"investment_assistant\",\n",
    "    {\"instructions\": initial_instructions, \"version\": 1}\n",
    ")\n",
    "\n",
    "print(\"Initialized procedural memory with base instructions\")\n",
    "print(f\"\\nCurrent Instructions (v1):\\n{initial_instructions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProceduralState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    feedback: str  # Optional feedback from user\n",
    "\n",
    "\n",
    "def get_instructions(store: BaseStore) -> tuple[str, int]:\n",
    "    \"\"\"Retrieve current instructions from procedural memory.\"\"\"\n",
    "    item = store.get((\"agent\", \"instructions\"), \"investment_assistant\")\n",
    "    if item is None:\n",
    "        return \"You are a helpful investment advisory assistant.\", 0\n",
    "    return item.value[\"instructions\"], item.value[\"version\"]\n",
    "\n",
    "\n",
    "def procedural_assistant_node(state: ProceduralState, config: RunnableConfig, *, store: BaseStore):\n",
    "    \"\"\"Respond using current procedural instructions.\"\"\"\n",
    "    instructions, version = get_instructions(store)\n",
    "    \n",
    "    messages = [SystemMessage(content=instructions)] + state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def reflection_node(state: ProceduralState, config: RunnableConfig, *, store: BaseStore):\n",
    "    \"\"\"Reflect on feedback and update instructions if needed.\"\"\"\n",
    "    feedback = state.get(\"feedback\", \"\")\n",
    "    \n",
    "    if not feedback:\n",
    "        return {}  # No feedback, no update needed\n",
    "    \n",
    "    # Get current instructions\n",
    "    current_instructions, version = get_instructions(store)\n",
    "    \n",
    "    # Ask the LLM to reflect and improve instructions\n",
    "    reflection_prompt = f\"\"\"You are improving an investment advisory assistant's instructions based on user feedback.\n",
    "\n",
    "Current Instructions:\n",
    "{current_instructions}\n",
    "\n",
    "User Feedback:\n",
    "{feedback}\n",
    "\n",
    "Based on this feedback, provide improved instructions. Keep the same general format but incorporate the feedback.\n",
    "Only output the new instructions, nothing else.\"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=reflection_prompt)])\n",
    "    new_instructions = response.content\n",
    "    \n",
    "    # Update procedural memory with new instructions\n",
    "    store.put(\n",
    "        (\"agent\", \"instructions\"),\n",
    "        \"investment_assistant\",\n",
    "        {\"instructions\": new_instructions, \"version\": version + 1}\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nInstructions updated to version {version + 1}\")\n",
    "    return {}\n",
    "\n",
    "\n",
    "def should_reflect(state: ProceduralState) -> str:\n",
    "    \"\"\"Decide whether to reflect on feedback.\"\"\"\n",
    "    if state.get(\"feedback\"):\n",
    "        return \"reflect\"\n",
    "    return \"end\"\n",
    "\n",
    "\n",
    "# Build the procedural memory graph\n",
    "builder5 = StateGraph(ProceduralState)\n",
    "builder5.add_node(\"assistant\", procedural_assistant_node)\n",
    "builder5.add_node(\"reflect\", reflection_node)\n",
    "\n",
    "builder5.add_edge(START, \"assistant\")\n",
    "builder5.add_conditional_edges(\"assistant\", should_reflect, {\"reflect\": \"reflect\", \"end\": END})\n",
    "builder5.add_edge(\"reflect\", END)\n",
    "\n",
    "procedural_graph = builder5.compile(\n",
    "    checkpointer=MemorySaver(),\n",
    "    store=semantic_store\n",
    ")\n",
    "\n",
    "print(\"Procedural memory graph ready (with self-improvement capability)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with initial instructions\n",
    "config = {\"configurable\": {\"thread_id\": \"procedural_thread_1\"}}\n",
    "\n",
    "response = procedural_graph.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"How should I think about portfolio risk?\")],\n",
    "        \"feedback\": \"\"  # No feedback yet\n",
    "    },\n",
    "    config\n",
    ")\n",
    "\n",
    "print(\"User: How should I think about portfolio risk?\")\n",
    "print(f\"\\nAssistant (v1 instructions):\\n{response['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now provide feedback - the agent will update its own instructions!\n",
    "response = procedural_graph.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"How should I think about portfolio risk?\")],\n",
    "        \"feedback\": \"Your responses are too long. Please be more concise and give me 3 actionable insights maximum.\"\n",
    "    },\n",
    "    {\"configurable\": {\"thread_id\": \"procedural_thread_2\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the updated instructions\n",
    "new_instructions, version = get_instructions(semantic_store)\n",
    "print(f\"Updated Instructions (v{version}):\\n\")\n",
    "print(new_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with updated instructions - should be more concise now!\n",
    "response = procedural_graph.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"What investment opportunities should I consider in the current market?\")],\n",
    "        \"feedback\": \"\"  # No feedback this time\n",
    "    },\n",
    "    {\"configurable\": {\"thread_id\": \"procedural_thread_3\"}}\n",
    ")\n",
    "\n",
    "print(f\"User: What investment opportunities should I consider in the current market?\")\n",
    "print(f\"\\nAssistant (v{version} instructions - after feedback):\")\n",
    "print(response['messages'][-1].content)\n",
    "print(\"\\nNotice: The response should now be more concise based on the feedback!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10: Unified Investment Memory Agent\n",
    "\n",
    "Now let's combine **all 5 memory types** into a unified investment advisory agent:\n",
    "\n",
    "1. **Short-term**: Remembers current conversation (checkpointer)\n",
    "2. **Long-term**: Stores user profile across sessions (store + namespace)\n",
    "3. **Semantic**: Retrieves relevant investment knowledge (store + embeddings)\n",
    "4. **Episodic**: Uses past successful interactions as examples (store + search)\n",
    "5. **Procedural**: Adapts behavior based on feedback (store + reflection)\n",
    "\n",
    "### Memory Retrieval Flow\n",
    "\n",
    "```\n",
    "User Query: \"What investment strategy suits my risk profile?\"\n",
    "              ‚îÇ\n",
    "              ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  1. PROCEDURAL: Get current instructions         ‚îÇ\n",
    "‚îÇ  2. LONG-TERM: Load user profile (constraints)   ‚îÇ\n",
    "‚îÇ  3. SEMANTIC: Search investment knowledge        ‚îÇ\n",
    "‚îÇ  4. EPISODIC: Find similar past interactions     ‚îÇ\n",
    "‚îÇ  5. SHORT-TERM: Include conversation history     ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "              ‚îÇ\n",
    "              ‚ñº\n",
    "        Generate personalized, informed response\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnifiedState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    user_id: str\n",
    "    feedback: str\n",
    "\n",
    "\n",
    "def unified_investment_assistant(state: UnifiedState, config: RunnableConfig, *, store: BaseStore):\n",
    "    \"\"\"An assistant that uses all five memory types.\"\"\"\n",
    "    user_id = state[\"user_id\"]\n",
    "    user_message = state[\"messages\"][-1].content\n",
    "    \n",
    "    # 1. PROCEDURAL: Get current instructions\n",
    "    instructions_item = store.get((\"agent\", \"instructions\"), \"investment_assistant\")\n",
    "    base_instructions = instructions_item.value[\"instructions\"] if instructions_item else \"You are a helpful investment advisory assistant.\"\n",
    "    \n",
    "    # 2. LONG-TERM: Get user profile\n",
    "    profile_items = list(store.search((user_id, \"profile\")))\n",
    "    pref_items = list(store.search((user_id, \"preferences\")))\n",
    "    profile_text = \"\\n\".join([f\"- {p.key}: {p.value}\" for p in profile_items]) if profile_items else \"No profile stored.\"\n",
    "    \n",
    "    # 3. SEMANTIC: Search for relevant knowledge\n",
    "    relevant_knowledge = store.search((\"investment\", \"knowledge\"), query=user_message, limit=2)\n",
    "    knowledge_text = \"\\n\".join([f\"- {r.value['text'][:200]}...\" for r in relevant_knowledge]) if relevant_knowledge else \"No specific knowledge found.\"\n",
    "    \n",
    "    # 4. EPISODIC: Find similar past interactions\n",
    "    similar_episodes = store.search((\"agent\", \"episodes\"), query=user_message, limit=1)\n",
    "    if similar_episodes:\n",
    "        ep = similar_episodes[0].value\n",
    "        episode_text = f\"Similar past interaction:\\nUser: {ep.get('input', 'N/A')}\\nResponse style: {ep.get('feedback', 'N/A')}\"\n",
    "    else:\n",
    "        episode_text = \"No similar past interactions found.\"\n",
    "    \n",
    "    # Build comprehensive system message\n",
    "    system_message = f\"\"\"{base_instructions}\n",
    "\n",
    "=== USER PROFILE ===\n",
    "{profile_text}\n",
    "\n",
    "=== RELEVANT INVESTMENT KNOWLEDGE ===\n",
    "{knowledge_text}\n",
    "\n",
    "=== LEARNING FROM EXPERIENCE ===\n",
    "{episode_text}\n",
    "\n",
    "Use all of this context to provide the best possible personalized response.\"\"\"\n",
    "    \n",
    "    # 5. SHORT-TERM: Full conversation history is automatically managed by the checkpointer\n",
    "    # Use summarization for long conversations\n",
    "    trimmed_messages = summarize_conversation(state[\"messages\"], max_messages=6)\n",
    "    \n",
    "    messages = [SystemMessage(content=system_message)] + trimmed_messages\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def unified_feedback_node(state: UnifiedState, config: RunnableConfig, *, store: BaseStore):\n",
    "    \"\"\"Update procedural memory based on feedback.\"\"\"\n",
    "    feedback = state.get(\"feedback\", \"\")\n",
    "    if not feedback:\n",
    "        return {}\n",
    "    \n",
    "    item = store.get((\"agent\", \"instructions\"), \"investment_assistant\")\n",
    "    if item is None:\n",
    "        return {}\n",
    "    \n",
    "    current = item.value\n",
    "    reflection_prompt = f\"\"\"Update these instructions based on feedback:\n",
    "\n",
    "Current: {current['instructions']}\n",
    "Feedback: {feedback}\n",
    "\n",
    "Output only the updated instructions.\"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=reflection_prompt)])\n",
    "    store.put(\n",
    "        (\"agent\", \"instructions\"),\n",
    "        \"investment_assistant\",\n",
    "        {\"instructions\": response.content, \"version\": current[\"version\"] + 1}\n",
    "    )\n",
    "    print(f\"Procedural memory updated to v{current['version'] + 1}\")\n",
    "    return {}\n",
    "\n",
    "\n",
    "def unified_route(state: UnifiedState) -> str:\n",
    "    return \"feedback\" if state.get(\"feedback\") else \"end\"\n",
    "\n",
    "\n",
    "# Build the unified graph\n",
    "unified_builder = StateGraph(UnifiedState)\n",
    "unified_builder.add_node(\"assistant\", unified_investment_assistant)\n",
    "unified_builder.add_node(\"feedback\", unified_feedback_node)\n",
    "\n",
    "unified_builder.add_edge(START, \"assistant\")\n",
    "unified_builder.add_conditional_edges(\"assistant\", unified_route, {\"feedback\": \"feedback\", \"end\": END})\n",
    "unified_builder.add_edge(\"feedback\", END)\n",
    "\n",
    "# Compile with both checkpointer (short-term) and store (all other memory types)\n",
    "unified_graph = unified_builder.compile(\n",
    "    checkpointer=MemorySaver(),\n",
    "    store=semantic_store\n",
    ")\n",
    "\n",
    "print(\"Unified investment assistant ready with all 5 memory types!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the unified assistant\n",
    "config = {\"configurable\": {\"thread_id\": \"unified_thread_1\"}}\n",
    "\n",
    "# First interaction - should use semantic + long-term + episodic memory\n",
    "response = unified_graph.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"What investment strategy would you recommend given my profile?\")],\n",
    "        \"user_id\": \"user_alex\",  # Alex has moderate risk tolerance and ESG preferences!\n",
    "        \"feedback\": \"\"\n",
    "    },\n",
    "    config\n",
    ")\n",
    "\n",
    "print(\"User: What investment strategy would you recommend given my profile?\")\n",
    "print(f\"\\nAssistant: {response['messages'][-1].content}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Memory types used:\")\n",
    "print(\"  Long-term: Knows Alex's risk tolerance, portfolio, and ESG preferences\")\n",
    "print(\"  Semantic: Retrieved investment knowledge from Stone Ridge letter\")\n",
    "print(\"  Episodic: May use similar advisory episode as reference\")\n",
    "print(\"  Procedural: Following current instructions\")\n",
    "print(\"  Short-term: Will remember this in follow-up questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow-up question (tests short-term memory)\n",
    "response = unified_graph.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"Can you tell me more about the alternative investments you mentioned?\")],\n",
    "        \"user_id\": \"user_alex\",\n",
    "        \"feedback\": \"\"\n",
    "    },\n",
    "    config  # Same thread\n",
    ")\n",
    "\n",
    "print(\"User: Can you tell me more about the alternative investments you mentioned?\")\n",
    "print(f\"\\nAssistant: {response['messages'][-1].content}\")\n",
    "print(\"\\nNotice: The agent remembers the context from the previous message!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚ùì Question #3:\n",
    "\n",
    "How would you decide what constitutes a **\"successful\" investment advisory interaction** worth storing as an episode? What metadata should you store alongside the episode?\n",
    "\n",
    "Consider:\n",
    "- Explicit feedback (thumbs up) vs implicit signals\n",
    "- User engagement (did they ask follow-up questions?)\n",
    "- Objective outcomes vs subjective satisfaction\n",
    "- Privacy implications of storing interaction data\n",
    "\n",
    "##### Answer:\n",
    "\n",
    "**Defining \"Successful\" Investment Interactions:**\n",
    "\n",
    "**Explicit Signals (Strongest):**\n",
    "1. **Direct Positive Feedback**\n",
    "   - User clicks \"helpful\" or gives thumbs up\n",
    "   - User explicitly says \"this was exactly what I needed\"\n",
    "   - User rates the interaction 4-5 stars\n",
    "\n",
    "2. **Actionable Follow-Through**\n",
    "   - User implements the advice (tracked through subsequent conversations)\n",
    "   - User returns to report positive outcomes\n",
    "   - User schedules a follow-up consultation\n",
    "\n",
    "**Implicit Signals (Moderate):**\n",
    "3. **Engagement Patterns**\n",
    "   - User asks thoughtful follow-up questions (indicates value)\n",
    "   - Longer session duration (suggests deep engagement)\n",
    "   - User bookmarks or saves the conversation\n",
    "   - User asks to schedule another consultation soon\n",
    "\n",
    "4. **Behavioral Indicators**\n",
    "   - User references this advice in future conversations\n",
    "   - No immediate pushback or confusion\n",
    "   - Clear understanding demonstrated in follow-ups\n",
    "\n",
    "**Anti-Patterns (NOT Successful):**\n",
    "- User asks for clarification repeatedly (advice was unclear)\n",
    "- User disputes or challenges the recommendation\n",
    "- User leaves mid-conversation\n",
    "- No follow-up engagement at all\n",
    "\n",
    "**Episodic Memory Metadata Schema:**\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"episode_id\": \"uuid-string\",\n",
    "    \"timestamp\": \"2025-01-15T14:30:00Z\",\n",
    "    \"user_id\": \"user_123\",  # Hashed/anonymized\n",
    "    \n",
    "    # Context\n",
    "    \"situation\": \"User with concentrated tech holdings seeking diversification\",\n",
    "    \"user_profile_snapshot\": {\n",
    "        \"risk_tolerance\": \"moderate\",\n",
    "        \"portfolio_size\": \"$500K\",\n",
    "        \"investment_horizon\": \"15 years\"\n",
    "    },\n",
    "    \n",
    "    # Interaction\n",
    "    \"user_query\": \"I have most of my portfolio in tech stocks. How should I diversify?\",\n",
    "    \"agent_response\": \"[full response text]\",\n",
    "    \"response_structure\": \"3-part framework: asset classes, geographies, action plan\",\n",
    "    \n",
    "    # Success Indicators\n",
    "    \"success_score\": 0.92,  # Composite score\n",
    "    \"explicit_feedback\": {\n",
    "        \"thumbs_up\": True,\n",
    "        \"rating\": 5,\n",
    "        \"comment\": \"Very helpful and actionable\"\n",
    "    },\n",
    "    \"implicit_signals\": {\n",
    "        \"follow_up_questions\": 2,\n",
    "        \"session_duration_seconds\": 480,\n",
    "        \"implemented_advice\": True  # from later conversation\n",
    "    },\n",
    "    \n",
    "    # Learning\n",
    "    \"what_worked\": \"Structured 3-part framework, specific percentages, phased approach\",\n",
    "    \"advisor_notes\": \"User responded well to visual breakdown and concrete action steps\",\n",
    "    \n",
    "    # Compliance & Privacy\n",
    "    \"anonymized\": True,\n",
    "    \"contains_pii\": False,\n",
    "    \"retention_days\": 730,  # 2 years\n",
    "    \"user_consent_for_storage\": True,\n",
    "    \n",
    "    # Embeddings for Semantic Search\n",
    "    \"embedding\": [0.1, 0.2, ...],  # 1536-dim vector\n",
    "    \"tags\": [\"diversification\", \"tech-heavy-portfolio\", \"moderate-risk\"]\n",
    "}\n",
    "```\n",
    "\n",
    "**Success Scoring Formula:**\n",
    "\n",
    "```python\n",
    "def calculate_success_score(episode_data: dict) -> float:\n",
    "    score = 0.0\n",
    "    \n",
    "    # Explicit feedback (60% weight)\n",
    "    if episode_data.get(\"explicit_feedback\"):\n",
    "        if episode_data[\"explicit_feedback\"].get(\"thumbs_up\"):\n",
    "            score += 0.3\n",
    "        rating = episode_data[\"explicit_feedback\"].get(\"rating\", 0)\n",
    "        score += (rating / 5.0) * 0.3  # Normalize to 0-0.3\n",
    "    \n",
    "    # Engagement (20% weight)\n",
    "    follow_ups = min(episode_data[\"implicit_signals\"].get(\"follow_up_questions\", 0), 5)\n",
    "    score += (follow_ups / 5.0) * 0.1\n",
    "    \n",
    "    session_duration = min(episode_data[\"implicit_signals\"].get(\"session_duration_seconds\", 0), 600)\n",
    "    score += (session_duration / 600.0) * 0.1\n",
    "    \n",
    "    # Implementation (20% weight)\n",
    "    if episode_data[\"implicit_signals\"].get(\"implemented_advice\"):\n",
    "        score += 0.2\n",
    "    \n",
    "    return min(score, 1.0)  # Cap at 1.0\n",
    "\n",
    "\n",
    "# Store only high-quality episodes\n",
    "if calculate_success_score(episode_data) >= 0.7:\n",
    "    store.put((\"agent\", \"episodes\"), episode_id, episode_data)\n",
    "```\n",
    "\n",
    "**Privacy Considerations:**\n",
    "\n",
    "1. **Anonymization**\n",
    "   - Hash user IDs before storage\n",
    "   - Remove or generalize specific portfolio values\n",
    "   - Strip out any mentioned names, addresses, or account numbers\n",
    "\n",
    "2. **User Consent**\n",
    "   - Explicitly ask users to opt-in to \"help improve our advisory service\"\n",
    "   - Provide clear data retention and usage policies\n",
    "   - Allow users to request deletion of their episodes\n",
    "\n",
    "3. **Regulatory Compliance**\n",
    "   - Ensure episodes don't violate fiduciary duty\n",
    "   - Maintain audit trail for compliance review\n",
    "   - Store episodes separately from user PII\n",
    "\n",
    "4. **Retention Policy**\n",
    "   - Keep episodes for limited time (e.g., 2 years)\n",
    "   - Automatically purge low-value episodes quarterly\n",
    "   - Archive successful episodes for model fine-tuning\n",
    "\n",
    "**When NOT to Store:**\n",
    "- Conversations involving errors or bad advice\n",
    "- Discussions of specific securities (insider trading concerns)\n",
    "- Interactions where user was frustrated or confused\n",
    "- Any conversation containing compliance violations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùì Question #4:\n",
    "\n",
    "For a **production investment advisory assistant**, which memory types need persistent storage (PostgreSQL) vs in-memory? How would you handle memory across multiple agent instances (e.g., Market Outlook Agent, Strategy Agent, Risk Management Agent)?\n",
    "\n",
    "Consider:\n",
    "- Which memories are user-specific vs shared?\n",
    "- Consistency requirements across agents\n",
    "- Memory expiration and cleanup policies\n",
    "- Namespace strategy for multi-agent systems\n",
    "\n",
    "##### Answer:\n",
    "\n",
    "**Memory Storage Architecture:**\n",
    "\n",
    "| Memory Type | Storage | Rationale | TTL Policy |\n",
    "|-------------|---------|-----------|------------|\n",
    "| **Short-term** | PostgreSQL (`PostgresSaver`) | Must survive restarts, user expects continuity | 30 days of inactivity |\n",
    "| **Long-term (User Profiles)** | PostgreSQL (`PostgresStore`) | Critical user data, must never lose | Never expire (unless user deletion) |\n",
    "| **Semantic (Knowledge Base)** | PostgreSQL + pgvector | Shared across all users, needs vector search | Update on new content |\n",
    "| **Episodic (Past Interactions)** | PostgreSQL | Learning resource, compliance audit trail | 2 years |\n",
    "| **Procedural (Instructions)** | PostgreSQL + Redis cache | Shared across users, needs versioning | Never expire, version history |\n",
    "\n",
    "**Why PostgreSQL vs In-Memory:**\n",
    "\n",
    "**Use PostgreSQL for:**\n",
    "- User-specific data (profiles, conversation history)\n",
    "- Compliance and audit requirements\n",
    "- Data that must survive server restarts\n",
    "- Multi-instance deployment (shared state)\n",
    "\n",
    "**Use In-Memory (Redis) for:**\n",
    "- Hot cache of frequently accessed data\n",
    "- Temporary session data (< 5 minutes)\n",
    "- Rate limiting and request tracking\n",
    "- Real-time feature flags\n",
    "\n",
    "**Multi-Agent Namespace Strategy:**\n",
    "\n",
    "```python\n",
    "# Namespace Format: (scope, category, [agent_name])\n",
    "\n",
    "# ===== SHARED MEMORIES (Cross-Agent) =====\n",
    "\n",
    "# User Profiles - accessible by ALL agents\n",
    "(user_id, \"profile\")              # User: risk tolerance, goals, constraints\n",
    "(user_id, \"preferences\")          # User: communication style, reporting frequency\n",
    "\n",
    "# Investment Knowledge Base - accessible by ALL agents\n",
    "(\"investment\", \"knowledge\")       # Semantic: Stone Ridge documents, market data\n",
    "(\"investment\", \"facts\")           # Semantic: General investment principles\n",
    "\n",
    "# ===== AGENT-SPECIFIC MEMORIES =====\n",
    "\n",
    "# Market Outlook Agent\n",
    "(\"market_agent\", \"instructions\")       # Procedural: Market agent's system prompt\n",
    "(\"market_agent\", \"episodes\")           # Episodic: Successful market analyses\n",
    "(user_id, \"market_agent\", \"history\")   # Short-term: User's market discussions\n",
    "\n",
    "# Strategy Agent  \n",
    "(\"strategy_agent\", \"instructions\")     # Procedural: Strategy agent's system prompt\n",
    "(\"strategy_agent\", \"episodes\")         # Episodic: Successful strategy consultations\n",
    "(user_id, \"strategy_agent\", \"history\") # Short-term: User's strategy discussions\n",
    "\n",
    "# Risk Management Agent\n",
    "(\"risk_agent\", \"instructions\")         # Procedural: Risk agent's system prompt\n",
    "(\"risk_agent\", \"episodes\")             # Episodic: Successful risk assessments\n",
    "(user_id, \"risk_agent\", \"history\")     # Short-term: User's risk discussions\n",
    "\n",
    "# ===== CROSS-AGENT LEARNING =====\n",
    "(\"agents\", \"shared_episodes\")          # Best practices any agent can learn from\n",
    "```\n",
    "\n",
    "**Cross-Agent Memory Sharing Example:**\n",
    "\n",
    "```python\n",
    "class MultiAgentMemoryManager:\n",
    "    def __init__(self, store: PostgresStore):\n",
    "        self.store = store\n",
    "    \n",
    "    def get_user_context(self, user_id: str) -> dict:\n",
    "        \"\"\"Get shared user context for ANY agent.\"\"\"\n",
    "        # All agents should know the user profile\n",
    "        profile = list(self.store.search((user_id, \"profile\")))\n",
    "        preferences = list(self.store.search((user_id, \"preferences\")))\n",
    "        \n",
    "        return {\n",
    "            \"profile\": {p.key: p.value for p in profile},\n",
    "            \"preferences\": {p.key: p.value for p in preferences}\n",
    "        }\n",
    "    \n",
    "    def get_agent_instructions(self, agent_name: str, version: int = None) -> str:\n",
    "        \"\"\"Get agent-specific procedural memory.\"\"\"\n",
    "        item = self.store.get((f\"{agent_name}\", \"instructions\"), \"current\")\n",
    "        if version is not None:\n",
    "            item = self.store.get((f\"{agent_name}\", \"instructions\"), f\"v{version}\")\n",
    "        return item.value[\"instructions\"]\n",
    "    \n",
    "    def search_cross_agent_episodes(self, query: str, limit: int = 3) -> list:\n",
    "        \"\"\"Search episodes from ALL agents for learning.\"\"\"\n",
    "        # Search shared episodes\n",
    "        shared = self.store.search((\"agents\", \"shared_episodes\"), query=query, limit=limit)\n",
    "        \n",
    "        # Could also search agent-specific episodes\n",
    "        market = self.store.search((\"market_agent\", \"episodes\"), query=query, limit=1)\n",
    "        strategy = self.store.search((\"strategy_agent\", \"episodes\"), query=query, limit=1)\n",
    "        risk = self.store.search((\"risk_agent\", \"episodes\"), query=query, limit=1)\n",
    "        \n",
    "        return list(shared) + list(market) + list(strategy) + list(risk)\n",
    "    \n",
    "    def log_agent_interaction(self, user_id: str, agent_name: str, \n",
    "                            query: str, response: str, success_score: float):\n",
    "        \"\"\"Log interaction for both agent-specific and potentially shared learning.\"\"\"\n",
    "        episode_id = str(uuid4())\n",
    "        \n",
    "        # Store in agent-specific namespace\n",
    "        self.store.put(\n",
    "            (f\"{agent_name}\", \"episodes\"),\n",
    "            episode_id,\n",
    "            {\n",
    "                \"user_id\": user_id,  # anonymized\n",
    "                \"query\": query,\n",
    "                \"response\": response,\n",
    "                \"success_score\": success_score,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # If highly successful, also add to shared learning\n",
    "        if success_score >= 0.9:\n",
    "            self.store.put(\n",
    "                (\"agents\", \"shared_episodes\"),\n",
    "                episode_id,\n",
    "                {\n",
    "                    \"source_agent\": agent_name,\n",
    "                    \"query\": query,\n",
    "                    \"response\": response,\n",
    "                    \"success_score\": success_score,\n",
    "                    \"what_worked\": \"Extracted from agent reflection\"\n",
    "                }\n",
    "            )\n",
    "```\n",
    "\n",
    "**Consistency & Concurrency:**\n",
    "\n",
    "1. **User Profile Updates**\n",
    "   - Use row-level locking in PostgreSQL\n",
    "   - Timestamp all updates, use \"last write wins\" strategy\n",
    "   - Invalidate Redis cache on write\n",
    "\n",
    "2. **Episodic Memory Collection**\n",
    "   - Each agent writes independently (no conflicts)\n",
    "   - Background job promotes high-quality episodes to shared namespace\n",
    "\n",
    "3. **Procedural Memory Updates**\n",
    "   - Version all instruction changes (v1, v2, v3...)\n",
    "   - Atomic updates with compare-and-swap\n",
    "   - Gradual rollout (A/B test new instructions)\n",
    "\n",
    "**Memory Cleanup Policies:**\n",
    "\n",
    "```python\n",
    "# Automated cleanup job (runs daily)\n",
    "def cleanup_memory_store(store: PostgresStore):\n",
    "    now = datetime.now()\n",
    "    \n",
    "    # 1. Delete inactive conversation threads (30 days)\n",
    "    for thread in store.search((\"*\", \"*\", \"history\")):\n",
    "        if (now - datetime.fromisoformat(thread.value[\"last_updated\"])).days > 30:\n",
    "            store.delete(thread.namespace, thread.key)\n",
    "    \n",
    "    # 2. Archive old episodes (2 years)\n",
    "    for episode in store.search((\"*\", \"episodes\")):\n",
    "        age_days = (now - datetime.fromisoformat(episode.value[\"timestamp\"])).days\n",
    "        if age_days > 730:\n",
    "            # Move to archive storage (S3) and delete from hot store\n",
    "            archive_episode(episode)\n",
    "            store.delete(episode.namespace, episode.key)\n",
    "    \n",
    "    # 3. Prune low-value episodes (quarterly)\n",
    "    for episode in store.search((\"*\", \"episodes\")):\n",
    "        if episode.value.get(\"success_score\", 0) < 0.5:\n",
    "            age_days = (now - datetime.fromisoformat(episode.value[\"timestamp\"])).days\n",
    "            if age_days > 90:  # Keep low-value for 90 days only\n",
    "                store.delete(episode.namespace, episode.key)\n",
    "    \n",
    "    # 4. User profiles: NEVER auto-delete (compliance + UX)\n",
    "    # 5. Procedural instructions: Keep all versions (audit trail)\n",
    "```\n",
    "\n",
    "**Deployment Architecture:**\n",
    "\n",
    "```\n",
    "                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "                    ‚îÇ   Load Balancer  ‚îÇ\n",
    "                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                             ‚îÇ\n",
    "            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "            ‚îÇ                ‚îÇ                ‚îÇ\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚îÇ   Agent      ‚îÇ ‚îÇ   Agent      ‚îÇ ‚îÇ   Agent      ‚îÇ\n",
    "    ‚îÇ Instance 1   ‚îÇ ‚îÇ Instance 2   ‚îÇ ‚îÇ Instance 3   ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            ‚îÇ                ‚îÇ                ‚îÇ\n",
    "            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                             ‚îÇ\n",
    "                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "                    ‚îÇ  Redis Cache     ‚îÇ\n",
    "                    ‚îÇ  (Hot data)      ‚îÇ\n",
    "                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                             ‚îÇ\n",
    "                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "                    ‚îÇ  PostgreSQL      ‚îÇ\n",
    "                    ‚îÇ  + pgvector      ‚îÇ\n",
    "                    ‚îÇ  (Persistent)    ‚îÇ\n",
    "                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "**Key Principles:**\n",
    "\n",
    "1. **User data = PostgreSQL** (persistent, multi-instance)\n",
    "2. **Shared knowledge = PostgreSQL** (semantic search with pgvector)\n",
    "3. **Hot cache = Redis** (performance)\n",
    "4. **Cross-agent learning = Shared namespaces**\n",
    "5. **Compliance = Never auto-delete user profiles or audit trails**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üèóÔ∏è Activity #2: Investment Memory Dashboard\n",
    "\n",
    "Build an investment tracking system that:\n",
    "1. Tracks investment metrics over time (portfolio value, risk score, allocation drift)\n",
    "2. Uses semantic memory to find relevant investment advice\n",
    "3. Uses episodic memory to recall what advisory approaches worked before\n",
    "4. Uses procedural memory to adapt advice style\n",
    "5. Provides a synthesized \"investment summary\"\n",
    "\n",
    "### Requirements:\n",
    "- Store at least 3 investment metrics per user\n",
    "- Track metrics over multiple \"days\" (simulated)\n",
    "- Agent should reference historical data in responses\n",
    "- Generate a personalized investment summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "def log_investment_metric(store, user_id: str, date: str, metric_type: str, value: float, notes: str = \"\"):\n",
    "    \"\"\"Log an investment metric for a user.\"\"\"\n",
    "    namespace = (user_id, \"metrics\")\n",
    "    metric_id = f\"{metric_type}_{date}\"\n",
    "    \n",
    "    store.put(\n",
    "        namespace,\n",
    "        metric_id,\n",
    "        {\n",
    "            \"date\": date,\n",
    "            \"metric_type\": metric_type,\n",
    "            \"value\": value,\n",
    "            \"notes\": notes,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "    )\n",
    "    print(f\"Logged {metric_type}={value} for {user_id} on {date}\")\n",
    "\n",
    "\n",
    "def get_investment_history(store, user_id: str, metric_type: str = None, days: int = 7) -> list:\n",
    "    \"\"\"Get investment history for a user.\"\"\"\n",
    "    namespace = (user_id, \"metrics\")\n",
    "    \n",
    "    # Get all metrics for user\n",
    "    all_metrics = list(store.search(namespace))\n",
    "    \n",
    "    # Filter by metric type if specified\n",
    "    if metric_type:\n",
    "        all_metrics = [m for m in all_metrics if m.value[\"metric_type\"] == metric_type]\n",
    "    \n",
    "    # Filter by date range\n",
    "    cutoff_date = (datetime.now() - timedelta(days=days)).date().isoformat()\n",
    "    recent_metrics = [m for m in all_metrics if m.value[\"date\"] >= cutoff_date]\n",
    "    \n",
    "    # Sort by date\n",
    "    recent_metrics.sort(key=lambda x: x.value[\"date\"])\n",
    "    \n",
    "    return recent_metrics\n",
    "\n",
    "\n",
    "store_activity2 = InMemoryStore(\n",
    "    index={\n",
    "        \"embed\": embeddings,\n",
    "        \"dims\": 1536,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Simulate user profile\n",
    "user_id_dash = \"user_dashboard_test\"\n",
    "store.put(\n",
    "    (user_id_dash, \"profile\"),\n",
    "    \"name\",\n",
    "    {\"value\": \"Emma Thompson\"}\n",
    ")\n",
    "store.put(\n",
    "    (user_id_dash, \"profile\"),\n",
    "    \"risk_tolerance\",\n",
    "    {\"value\": \"moderate\"}\n",
    ")\n",
    "store.put(\n",
    "    (user_id_dash, \"profile\"),\n",
    "    \"portfolio_size\",\n",
    "    {\"value\": \"$750K\"}\n",
    ")\n",
    "\n",
    "# Simulate a week of investment metrics\n",
    "base_portfolio_value = 750000\n",
    "base_risk_score = 6.5  # out of 10\n",
    "base_allocation_drift = 2.0  # percentage points from target\n",
    "\n",
    "for i in range(7):\n",
    "    date = (datetime.now() - timedelta(days=6-i)).date().isoformat()\n",
    "    \n",
    "    # Simulate market volatility\n",
    "    daily_return = random.uniform(-0.02, 0.03)  # -2% to +3%\n",
    "    portfolio_value = base_portfolio_value * (1 + daily_return * i/7)\n",
    "    \n",
    "    # Risk score increases with market volatility\n",
    "    risk_score = base_risk_score + random.uniform(-0.5, 0.5)\n",
    "    \n",
    "    # Allocation drift increases over time without rebalancing\n",
    "    allocation_drift = base_allocation_drift + (i * 0.3)\n",
    "    \n",
    "    log_investment_metric(store_activity2, user_id_dash, date, \"portfolio_value\", portfolio_value, \n",
    "                         f\"Market {'up' if daily_return > 0 else 'down'}\")\n",
    "    log_investment_metric(store_activity2, user_id_dash, date, \"risk_score\", risk_score,\n",
    "                         \"Risk assessment based on VaR and portfolio beta\")\n",
    "    log_investment_metric(store_activity2, user_id_dash, date, \"allocation_drift\", allocation_drift,\n",
    "                         \"Drift from 60/40 target allocation\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Created 7 days of investment metrics for Emma Thompson\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "# Add some investment knowledge to semantic memory\n",
    "investment_knowledge_items = [\n",
    "    (\"advice_rebalance\", {\n",
    "        \"text\": \"When portfolio allocation drifts more than 5% from target, consider rebalancing to maintain risk profile and ensure alignment with investment goals. Rebalancing helps buy low and sell high systematically.\"\n",
    "    }),\n",
    "    (\"advice_volatility\", {\n",
    "        \"text\": \"During periods of high volatility (VIX > 25), consider adding defensive positions or tail risk hedges. Quality bonds and gold often provide portfolio stability in turbulent markets.\"\n",
    "    }),\n",
    "    (\"advice_risk_score\", {\n",
    "        \"text\": \"A risk score above 7 suggests elevated portfolio volatility. For moderate-risk investors, consider reducing equity exposure or adding low-correlation alternatives like reinsurance or managed futures.\"\n",
    "    })\n",
    "]\n",
    "\n",
    "advice_namespace = (\"investment\", \"advisory_knowledge\")\n",
    "for key, value in investment_knowledge_items:\n",
    "    store_activity2.put(advice_namespace, key, value)\n",
    "\n",
    "# Add episodic memory - successful past advisory approaches\n",
    "episode_rebalancing = {\n",
    "    \"text\": \"User had 8% allocation drift and received rebalancing advice\",\n",
    "    \"situation\": \"Portfolio drift exceeding comfort zone\",\n",
    "    \"advice_given\": \"Created phased rebalancing plan over 3 months to minimize tax impact and market timing risk\",\n",
    "    \"user_response\": \"Implemented successfully, reported reduced anxiety about portfolio\"\n",
    "}\n",
    "\n",
    "store_activity2.put(\n",
    "    (\"agent\", \"episodes\"),\n",
    "    \"episode_rebalancing_success\",\n",
    "    episode_rebalancing\n",
    ")\n",
    "\n",
    "print(\"Added investment knowledge and episodic memories to store\")\n",
    "\n",
    "\n",
    "# Build an investment dashboard agent that:\n",
    "#   - Retrieves user's investment history\n",
    "#   - Searches for relevant advice based on patterns\n",
    "#   - Uses episodic memory for what worked before\n",
    "#   - Generates a personalized summary\n",
    "\n",
    "class DashboardState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    user_id: str\n",
    "\n",
    "\n",
    "def investment_dashboard_agent(state: DashboardState, config: RunnableConfig, *, store: BaseStore):\n",
    "    \"\"\"Investment dashboard agent with all 5 memory types.\"\"\"\n",
    "    user_id = state[\"user_id\"]\n",
    "    user_query = state[\"messages\"][-1].content\n",
    "    \n",
    "    # 1. LONG-TERM: Get user profile\n",
    "    profile_items = list(store.search((user_id, \"profile\")))\n",
    "    profile = {p.key: p.value[\"value\"] for p in profile_items}\n",
    "    \n",
    "    # 2. HISTORICAL DATA: Get investment metrics (last 7 days)\n",
    "    metrics = get_investment_history(store, user_id, days=7)\n",
    "    \n",
    "    # Organize metrics by type\n",
    "    portfolio_values = [m for m in metrics if m.value[\"metric_type\"] == \"portfolio_value\"]\n",
    "    risk_scores = [m for m in metrics if m.value[\"metric_type\"] == \"risk_score\"]\n",
    "    allocation_drifts = [m for m in metrics if m.value[\"metric_type\"] == \"allocation_drift\"]\n",
    "    \n",
    "    # Calculate trends\n",
    "    if len(portfolio_values) >= 2:\n",
    "        value_change = portfolio_values[-1].value[\"value\"] - portfolio_values[0].value[\"value\"]\n",
    "        value_pct_change = (value_change / portfolio_values[0].value[\"value\"]) * 100\n",
    "    else:\n",
    "        value_pct_change = 0\n",
    "    \n",
    "    current_risk = risk_scores[-1].value[\"value\"] if risk_scores else 0\n",
    "    current_drift = allocation_drifts[-1].value[\"value\"] if allocation_drifts else 0\n",
    "    \n",
    "    # Build metrics summary\n",
    "    metrics_summary = f\"\"\"\n",
    "PORTFOLIO METRICS (Last 7 Days):\n",
    "- Portfolio Value: ${portfolio_values[-1].value['value']:,.0f} ({value_pct_change:+.2f}%)\n",
    "- Current Risk Score: {current_risk:.1f}/10\n",
    "- Allocation Drift: {current_drift:.1f}% from target\n",
    "\n",
    "WEEKLY TREND:\n",
    "- {'Portfolio grew' if value_pct_change > 0 else 'Portfolio declined'} by {abs(value_pct_change):.2f}%\n",
    "- Risk score: {'increased' if current_risk > 6.5 else 'stable or decreased'}\n",
    "- Allocation drift: {'increasing - rebalancing may be needed' if current_drift > 5 else 'within acceptable range'}\n",
    "\"\"\"\n",
    "    \n",
    "    # 3. SEMANTIC: Search for relevant advice based on current metrics\n",
    "    advice_queries = []\n",
    "    if current_drift > 5:\n",
    "        advice_queries.append(\"portfolio allocation drift rebalancing\")\n",
    "    if current_risk > 7:\n",
    "        advice_queries.append(\"high risk score portfolio volatility\")\n",
    "    if value_pct_change < -3:\n",
    "        advice_queries.append(\"portfolio decline market downturn\")\n",
    "    \n",
    "    relevant_advice = []\n",
    "    for query in advice_queries:\n",
    "        results = store.search((\"investment\", \"advisory_knowledge\"), query=query, limit=1)\n",
    "        relevant_advice.extend(results)\n",
    "    \n",
    "    advice_text = \"\\n\\n\".join([f\"- {r.value['text']}\" for r in relevant_advice]) if relevant_advice else \"No specific advice triggered.\"\n",
    "    \n",
    "    # 4. EPISODIC: Search for similar past situations\n",
    "    situation_query = f\"portfolio drift {current_drift}% risk score {current_risk}\"\n",
    "    similar_episodes = store.search((\"agent\", \"episodes\"), query=situation_query, limit=1)\n",
    "    \n",
    "    episodic_context = \"\"\n",
    "    if similar_episodes:\n",
    "        ep = similar_episodes[0].value\n",
    "        episodic_context = f\"\"\"\n",
    "LEARNING FROM PAST SUCCESS:\n",
    "Previous similar situation: {ep['situation']}\n",
    "What worked: {ep['advice_given']}\n",
    "User outcome: {ep['user_response']}\n",
    "\"\"\"\n",
    "    \n",
    "    # 5. PROCEDURAL: Build system prompt with all context\n",
    "    system_prompt = f\"\"\"You are an Investment Dashboard Assistant for {profile.get('name', 'the user')}.\n",
    "\n",
    "USER PROFILE:\n",
    "{chr(10).join([f\"- {k}: {v}\" for k, v in profile.items()])}\n",
    "\n",
    "{metrics_summary}\n",
    "\n",
    "RELEVANT INVESTMENT ADVICE:\n",
    "{advice_text}\n",
    "\n",
    "{episodic_context}\n",
    "\n",
    "Your task: Provide a concise, actionable investment summary. Reference specific metrics and trends. \n",
    "Suggest 1-2 concrete next steps based on the data. Be supportive but data-driven.\"\"\"\n",
    "    \n",
    "    # Generate response\n",
    "    messages = [SystemMessage(content=system_prompt)] + state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Build the dashboard graph\n",
    "builder_dashboard = StateGraph(DashboardState)\n",
    "builder_dashboard.add_node(\"dashboard\", investment_dashboard_agent)\n",
    "builder_dashboard.add_edge(START, \"dashboard\")\n",
    "builder_dashboard.add_edge(\"dashboard\", END)\n",
    "\n",
    "dashboard_graph = builder_dashboard.compile(\n",
    "    checkpointer=MemorySaver(),\n",
    "    store=store_activity2\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Investment Dashboard Agent ready!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "# Step 4: Test the dashboard\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST 1: Portfolio Performance Summary\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "response1 = dashboard_graph.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"Give me a summary of my portfolio performance this week.\")],\n",
    "        \"user_id\": user_id_dash\n",
    "    },\n",
    "    {\"configurable\": {\"thread_id\": \"dashboard_thread_1\"}}\n",
    ")\n",
    "\n",
    "print(f\"\\nUser: Give me a summary of my portfolio performance this week.\")\n",
    "print(f\"\\nDashboard Agent:\\n{response1['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST 2: Addressing Portfolio Volatility\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "response2 = dashboard_graph.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"My portfolio has been volatile lately and I'm seeing allocation drift. What should I do?\")],\n",
    "        \"user_id\": user_id_dash\n",
    "    },\n",
    "    {\"configurable\": {\"thread_id\": \"dashboard_thread_2\"}}\n",
    ")\n",
    "\n",
    "print(f\"\\nUser: My portfolio has been volatile lately and I'm seeing allocation drift. What should I do?\")\n",
    "print(f\"\\nDashboard Agent:\\n{response2['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DASHBOARD SUMMARY:\")\n",
    "print(\"The agent successfully used:\")\n",
    "print(\"‚úì Long-term memory: User profile (name, risk tolerance)\")\n",
    "print(\"‚úì Historical metrics: 7 days of portfolio/risk/drift data\")\n",
    "print(\"‚úì Semantic memory: Retrieved relevant investment advice\")\n",
    "print(\"‚úì Episodic memory: Referenced past successful rebalancing advice\")\n",
    "print(\"‚úì Short-term memory: Maintains conversation context across questions\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "In this module, we explored the **5 memory types** from the CoALA framework:\n",
    "\n",
    "| Memory Type | LangGraph Component | Scope | Investment Use Case |\n",
    "|-------------|---------------------|-------|-------------------|\n",
    "| **Short-term** | `MemorySaver` + `thread_id` | Within thread | Current consultation |\n",
    "| **Long-term** | `InMemoryStore` + namespaces | Across threads | User profile, goals, constraints |\n",
    "| **Semantic** | Store + embeddings + `search()` | Across threads | Investment knowledge retrieval |\n",
    "| **Episodic** | Store + few-shot examples | Across threads | Past successful interactions |\n",
    "| **Procedural** | Store + self-reflection | Across threads | Self-improving instructions |\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Memory transforms chatbots into advisors** - Persistence enables personalization\n",
    "2. **Different memory types serve different purposes** - Choose based on your use case\n",
    "3. **Context management is critical** - Trim and summarize to stay within limits\n",
    "4. **Episodic memory enables learning** - Show, don't just tell\n",
    "5. **Procedural memory enables adaptation** - Agents can improve themselves\n",
    "\n",
    "### Production Considerations:\n",
    "\n",
    "- Use `PostgresSaver` instead of `MemorySaver` for persistent checkpoints\n",
    "- Use `PostgresStore` instead of `InMemoryStore` for persistent long-term memory\n",
    "- Consider TTL (Time-to-Live) policies for automatic memory cleanup\n",
    "- Implement proper access controls for user data\n",
    "- Ensure compliance with financial regulations for investment advisory data\n",
    "\n",
    "### Further Reading:\n",
    "\n",
    "- [LangGraph Memory Documentation](https://langchain-ai.github.io/langgraph/concepts/memory/)\n",
    "- [CoALA Paper](https://arxiv.org/abs/2309.02427) - Cognitive Architectures for Language Agents\n",
    "- [LangGraph Platform](https://docs.langchain.com/langgraph-platform/) - Managed infrastructure for production"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
